{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more complex version of this would use this pygithub package as shown in here:\n",
    "- https://python.langchain.com/docs/integrations/toolkits/github\n",
    "\n",
    "But let's try a simpler version that just sets up a bunch of python functions to automate different github actions like add, commit and pull requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple commit to a branch of some repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll create a github repository using some simple commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git init -b main\n",
    "\n",
    "# git add . && git commit -m \"Some commit\"\n",
    "\n",
    "# gh repo create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try asking an agent to write come code and commit the resulting code to the current branch of this repository.\n",
    "\n",
    "To do that, let's give the agent the necessary tools it will need which in this case will be python functions that perform different github actions using the `subprocess` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll follow the basic steps for building a langchain agent:\n",
    "\n",
    "# Steps for building a simple agent:\n",
    "- Set up the LLM\n",
    "- Define the tool or toolkit (list of tools)\n",
    "- Set up a prompt template\n",
    "- Connect llm with your tools\n",
    "- Define your agent as a dict with keys: input, and agent scratchpad \n",
    "- Use the Langchain LCEL language to pipe agent, prompt the llm_with_tools variable and the output parser (which can use OpenAI function calling parser)\n",
    "- Create the agent loop\n",
    "- Wrap everything into the AgentExecutor\n",
    "- Invoke the agent with some query input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the llm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a tool for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def github_commit_tool(commit_message=\"Some commit\"):\n",
    "    subprocess.run([\"git\", \"add\", \".\"])\n",
    "    subprocess.run([\"git\", \"commit\", \"-m\", commit_message])\n",
    "    \n",
    "    return \"Committed to Github\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now! Before we use it with langchain, let's test it by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define tool\n",
    "from langchain.tools import tool\n",
    "import os\n",
    "import nbformat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def turn_jupyter_notebook_into_python_script(jupyter_notebook_path: str) -> None:\n",
    "        \"\"\"Turn a jupyter notebook into a python script or a text file\"\"\"\n",
    "        # Load the notebook\n",
    "        output_file_path=\"./output_notebook.txt\" \n",
    "        file_type='txt'\n",
    "        with open(jupyter_notebook_path) as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "        \n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "        \n",
    "        # Convert the notebook to a Python script or a text file\n",
    "        if file_type == 'py':\n",
    "            nbformat.write(nb, output_file_path)\n",
    "        elif file_type == 'txt':\n",
    "            with open(output_file_path, 'w') as f:\n",
    "                for cell in nb.cells:\n",
    "                    if cell.cell_type == 'code':\n",
    "                        f.write(cell.source + '\\n\\n')\n",
    "                    elif cell.cell_type == 'markdown':\n",
    "                        f.write(cell.source + '\\n\\n')\n",
    "        else:\n",
    "            raise ValueError('Invalid file type. Must be \"py\" or \"txt\".')\n",
    "        \n",
    "        \n",
    "tools = [turn_jupyter_notebook_into_python_script]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# setup prompt template\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are very powerful assistant that helps me write reports for machine learning related tasks.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# connect llm with your tools\n",
    "\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent = {\"input\": lambda x: x[\"input\"],\n",
    "         \"agent_scratchpad\": lambda x: format_to_openai_functions(x[\"intermediate_steps\"]),\n",
    "         } | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent.invoke({\n",
    "    \"input\": \"I want to write a report from this notebook I've written here: ./reporting_agent_langchain.ipynb\",\n",
    "    \"intermediate_steps\": []})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain.schema.agent import AgentFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly_agents",
   "language": "python",
   "name": "oreilly_agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
